{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/amazonreviews/test.ft.txt.bz2\n",
      "/kaggle/input/amazonreviews/train.ft.txt.bz2\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amazonreviews']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import fasttext\n",
    "import bz2\n",
    "import csv\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import os\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Load the training data \n",
    "data = bz2.BZ2File(\"../input/amazonreviews/train.ft.txt.bz2\")\n",
    "data = data.readlines()\n",
    "data = [x.decode('utf-8') for x in data[:10000]]\n",
    "print(len(data)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"__label__2 The best soundtrack ever to anything.: I'm reading a lot of reviews saying that this is the best 'game soundtrack' and I figured that I'd write a review to disagree a bit. This in my opinino is Yasunori Mitsuda's ultimate masterpiece. The music is timeless and I'm been listening to it for years now and its beauty simply refuses to fade.The price tag on this is pretty staggering I must say, but if you are going to buy any cd for this much money, this is the only one that I feel would be worth every penny.\\n\",\n",
       " '__label__2 Amazing!: This soundtrack is my favorite music of all time, hands down. The intense sadness of \"Prisoners of Fate\" (which means all the more if you\\'ve played the game) and the hope in \"A Distant Promise\" and \"Girl who Stole the Star\" have been an important inspiration to me personally throughout my teen years. The higher energy tracks like \"Chrono Cross ~ Time\\'s Scar~\", \"Time of the Dreamwatch\", and \"Chronomantique\" (indefinably remeniscent of Chrono Trigger) are all absolutely superb as well.This soundtrack is amazing music, probably the best of this composer\\'s work (I haven\\'t heard the Xenogears soundtrack, so I can\\'t say for sure), and even if you\\'ve never played the game, it would be worth twice the price to buy it.I wish I could give it 6 stars.\\n']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__label__1', '__label__2'] are the labels or targets the model is predicting\n"
     ]
    }
   ],
   "source": [
    "# Data Prep\n",
    "data = pd.DataFrame(data)\n",
    "data.to_csv(\"train.txt\", index=False, sep=' ', header=False, quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\" \")\n",
    "\n",
    "# Modelling\n",
    "\n",
    "model = fasttext.train_supervised('train.txt',label_prefix='__label__', thread=4, epoch = 10)\n",
    "print(model.labels, 'are the labels or targets the model is predicting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 number of records in the test set\n"
     ]
    }
   ],
   "source": [
    "# Load the test data\n",
    "test = bz2.BZ2File(\"../input/amazonreviews/test.ft.txt.bz2\")\n",
    "test = test.readlines()\n",
    "test = [x.decode('utf-8') for x in test[:10000]]\n",
    "print(len(test), 'number of records in the test set') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__label__2'] is the predicted label\n",
      "['__label__2'] is the probability score\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# To run the predict function, we need to remove the __label__1 and __label__2 from the testset.  \n",
    "new = [w.replace('__label__2 ', '') for w in test]\n",
    "new = [w.replace('__label__1 ', '') for w in new]\n",
    "new = [w.replace('\\n', '') for w in new]\n",
    "\n",
    "# Use the predict function \n",
    "pred = model.predict(new)\n",
    "\n",
    "# check the first record outputs\n",
    "print(pred[0][0], 'is the predicted label')\n",
    "print(pred[0][1], 'is the probability score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8406629143214509\n"
     ]
    }
   ],
   "source": [
    "# Lets recode the actual targets to 1's and 0's from both the test set and the actual predictions  \n",
    "labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in test]\n",
    "pred_labels = [0 if x == ['__label__1'] else 1 for x in pred[0]]\n",
    "\n",
    "# run the accuracy measure. \n",
    "print(roc_auc_score(labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
