{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.python.keras import models, layers, optimizers\nimport tensorflow\nfrom tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport bz2\nfrom sklearn.metrics import f1_score, roc_auc_score, accuracy_score\nimport re\n\n%matplotlib inline\n\nimport os\nprint(os.listdir(\"../input\"))\n","execution_count":1,"outputs":[{"output_type":"stream","text":"['amazonreviews']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom sklearn.model_selection import train_test_split\nfrom keras import layers\nfrom keras.layers.core import Activation, Dense\nfrom keras.layers.embeddings import Embedding\nfrom keras.layers.recurrent import LSTM\nfrom keras.models import Sequential","execution_count":36,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data proprecessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Read the text\ndef get_labels_and_texts(file):\n    labels = []\n    texts = []\n    for line in bz2.BZ2File(file):\n        x = line.decode(\"utf-8\")\n        labels.append(int(x[9]) - 1)\n        texts.append(x[10:].strip())\n    return np.array(labels[:10000]), texts[:10000]\ntrain_labels, train_texts = get_labels_and_texts('../input/amazonreviews/train.ft.txt.bz2')\ntest_labels, test_texts = get_labels_and_texts('../input/amazonreviews/test.ft.txt.bz2')","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nNON_ALPHANUM = re.compile(r'[\\W]')\nNON_ASCII = re.compile(r'[^a-z0-1\\s]')\ndef normalize_texts(texts):\n    normalized_texts = []\n    for text in texts:\n        lower = text.lower()\n        no_punctuation = NON_ALPHANUM.sub(r' ', lower)\n        no_non_ascii = NON_ASCII.sub(r'', no_punctuation)\n        normalized_texts.append(no_non_ascii)\n    return normalized_texts\n        \ntrain_texts = normalize_texts(train_texts)\ntest_texts = normalize_texts(test_texts)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\ntoken=re.compile('[A-Za-z]+| [!?.,()\\']')\ndef reg_text(text):\n    \n    new_text=token.findall(text)\n    \n    new_text=[word.lower() for word in new_text]\n    return new_text","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def vector_generator(x):\n    \n    #x = pd.DataFrame(x,columns=['text'])\n    x['text']=x.text.apply(reg_text)\n    word_set=set()\n    for text in x.text:\n        for word in text:\n            word_set.add(word)\n    word_list=list(word_set)  \n   \n\n    word_index=dict( (word,word_list.index(word)) for word in word_list )\n    data_input=x.text.apply(lambda x: [word_index.get(word, 0) for word in x])\n    \n    maxlen=max(len(x)for x in data_input)\n    maxword=len(word_list)+1\n    \n    data_input=keras.preprocessing.sequence.pad_sequences(data_input.values,maxlen=maxlen)\n    \n    return data_input, maxlen, maxword\n    ","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x = pd.DataFrame(train_texts,columns=['text'])\ntest_x  = pd.DataFrame(test_texts,columns=['text'])\n\n\ndata=pd.concat([train_x,test_x]) \ndata.head()","execution_count":60,"outputs":[{"output_type":"execute_result","execution_count":60,"data":{"text/plain":"                                                text\n0  stuning even for the non gamer  this sound tra...\n1  the best soundtrack ever to anything   i m rea...\n2  amazing   this soundtrack is my favorite music...\n3  excellent soundtrack  i truly like this soundt...\n4  remember  pull your jaw off the floor after he...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>stuning even for the non gamer  this sound tra...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>the best soundtrack ever to anything   i m rea...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>amazing   this soundtrack is my favorite music...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>excellent soundtrack  i truly like this soundt...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>remember  pull your jaw off the floor after he...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Generate train set and text set\ndata, maxlen, maxword =vector_generator(data)\n\ndata_input=data[:10000]\ndata_test=data[10000:]","execution_count":66,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# generate training set and test set\nXtrain, Xtest, ytrain, ytest = train_test_split(data_input, train_labels, test_size=0.2, random_state=42)","execution_count":67,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Build model  and Train model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build LSTM model\nmodel = Sequential()\nmodel.add(layers.Embedding(maxword,1024,input_length=maxlen))\n\nmodel.add(layers.LSTM(1024,dropout=0.5, recurrent_dropout=0.5))\n\n\n#model.add( layers.Dense(522,kernel_regularizer=regularizers.l2(0.1),activation='relu') )\n#model.add( layers.Dropout(0.5) )\n\n\n\nmodel.add(Dense(1,activation=\"sigmoid\"))\n\nmodel.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=[\"accuracy\"])","execution_count":68,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(Xtrain, ytrain, batch_size=200, epochs=12,validation_data=(Xtest, ytest))","execution_count":69,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n","name":"stderr"},{"output_type":"stream","text":"Train on 8000 samples, validate on 2000 samples\nEpoch 1/12\n8000/8000 [==============================] - 24s 3ms/step - loss: 0.6444 - accuracy: 0.6315 - val_loss: 0.5409 - val_accuracy: 0.7085\nEpoch 2/12\n8000/8000 [==============================] - 23s 3ms/step - loss: 0.4323 - accuracy: 0.8150 - val_loss: 0.3785 - val_accuracy: 0.8455\nEpoch 3/12\n8000/8000 [==============================] - 23s 3ms/step - loss: 0.2936 - accuracy: 0.8859 - val_loss: 0.5047 - val_accuracy: 0.7520\nEpoch 4/12\n8000/8000 [==============================] - 23s 3ms/step - loss: 0.2178 - accuracy: 0.9204 - val_loss: 0.3987 - val_accuracy: 0.8405\nEpoch 5/12\n8000/8000 [==============================] - 23s 3ms/step - loss: 0.1536 - accuracy: 0.9464 - val_loss: 0.6469 - val_accuracy: 0.8240\nEpoch 6/12\n8000/8000 [==============================] - 23s 3ms/step - loss: 0.1441 - accuracy: 0.9495 - val_loss: 0.5512 - val_accuracy: 0.8360\nEpoch 7/12\n8000/8000 [==============================] - 23s 3ms/step - loss: 0.1083 - accuracy: 0.9665 - val_loss: 0.4727 - val_accuracy: 0.8435\nEpoch 8/12\n8000/8000 [==============================] - 23s 3ms/step - loss: 0.0714 - accuracy: 0.9761 - val_loss: 0.5699 - val_accuracy: 0.8370\nEpoch 9/12\n8000/8000 [==============================] - 23s 3ms/step - loss: 0.0424 - accuracy: 0.9864 - val_loss: 0.7741 - val_accuracy: 0.7795\nEpoch 10/12\n8000/8000 [==============================] - 23s 3ms/step - loss: 0.0498 - accuracy: 0.9831 - val_loss: 0.7652 - val_accuracy: 0.8090\nEpoch 11/12\n8000/8000 [==============================] - 23s 3ms/step - loss: 0.0307 - accuracy: 0.9914 - val_loss: 0.7529 - val_accuracy: 0.8275\nEpoch 12/12\n8000/8000 [==============================] - 23s 3ms/step - loss: 0.0168 - accuracy: 0.9959 - val_loss: 0.8983 - val_accuracy: 0.8155\n","name":"stdout"},{"output_type":"execute_result","execution_count":69,"data":{"text/plain":"<keras.callbacks.callbacks.History at 0x7f5dad89ef28>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Prodiction and evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(data_test)\n\n\npred_ = [1 if x > 0.5 else 0 for x in pred]","execution_count":92,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(roc_auc_score(test_labels, pred_))","execution_count":93,"outputs":[{"output_type":"stream","text":"0.7960350218886804\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}